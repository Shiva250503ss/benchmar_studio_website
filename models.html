<!DOCTYPE html>
<html lang="en">
  <head>
    <style>
      body { font-family: Arial, sans-serif; line-height: 1.6; margin: 20px; }
      h1, h2 { color: #333; }
      code { background-color: #f4f4f4; padding: 2px 4px; border-radius: 4px; }
      pre { background-color: #f4f4f4; padding: 10px; border-radius: 4px; overflow-x: auto; }
      img { max-width: 100%; height: auto; }
      .placeholder { color: #888; font-style: italic; }
      .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
}
  </style>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Benchmark Studio</title>
    <link rel="stylesheet" href="style.css" />
    <link rel="stylesheet" href="mediaqueries.css" />
  </head>
  <body>
    <nav id="desktop-nav">
        <div class="logo">Benchmark Studio</div>
        <div>
          <ul class="nav-links">
            <li><a href="index.html">Home</a></li>
            <li><a href="introduction.html">Introduction</a></li>
            <li><a href="EDA.html">Data Exploration</a></li>
            <li><a href="models.html">Models Implemented</a></li>
            <li><a href="">Conclusion</a></li>
            <li><a href="team.html">Team</a></li>
          </ul>
        </div>
      </nav>
      <nav id="hamburger-nav">
        <div class="logo">Benchmark Studio</div>
        <div class="hamburger-menu">
          <div class="hamburger-icon" onclick="toggleMenu()">
            <span></span>
            <span></span>
            <span></span>
          </div>
          <div class="menu-links">
            <li><a href="#about" onclick="toggleMenu()">Introduction</a></li>
            <li><a href="" onclick="toggleMenu()">Data Exploration</a></li>
            <li><a href="" onclick="toggleMenu()">Models Implemented</a></li>
            <li><a href="" onclick="toggleMenu()">Conclusion</a></li>
            <li><a href="" onclick="toggleMenu()">Team</a></li>
          </div>
        </div>
      </nav>    
    <section id="background-image-section2"></section>
    <br>
    <h1 class="title">LLM Models Performance Comparison Analysis</h1>
    <!DOCTYPE html>
<html>
<head>
    <title>Models Implementation</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 20px; }
        h1, h2 { color: #333; }
        code { background-color: #f4f4f4; padding: 2px 4px; border-radius: 4px; }
        pre { background-color: #f4f4f4; padding: 10px; border-radius: 4px; overflow-x: auto; }
        img { max-width: 100%; height: auto; }
        .placeholder { color: #888; font-style: italic; }
        .box {
            border: 1px solid #ccc;
            padding: 15px;
            margin-bottom: 20px;
            border-radius: 5px;
            background-color: #f9f9f9;
        }
        .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
}

    </style>
</head>
<body>



<h2>Comparison of Old and New Dataset</h2>
<div class="box">
    <p>
        In our ongoing efforts to refine our model training processes, we have updated our datasets to enhance data quality and consistency. Below, we illustrate the structural and content-related improvements between the original and the revised datasets.
    </p>
    <div class="image-container">
        <img src="assets/oldds.jpg" alt="Old Dataset Overview" width="1000" class ="center">
        <br>
        <img src="assets/newds.jpg" alt="New Cleaned Dataset Overview" width="1000" class ="center">
    </div>
    <p>
        The initial dataset, depicted in the first image, included various metrics such as language detection, refusal flags, and comprehensive token counts, along with qualitative assessments like information fulfillment and technical accuracy. The second image showcases our cleaned dataset, which now features:
<br>
               <li>Enhanced data structure with consistent and uniform fields across records.</li><br>
               <li>Removal of extraneous columns to focus on core metrics critical to model evaluation.</li><br>
               <li>Standardization of entries including timestamp conversions to improve readability and analysis feasibility.</li><br>

        <br>
        These changes ensure that our dataset is not only streamlined but also optimized for more effective model training and performance evaluation.
    </p>
</div>
<h1>Models Implementation</h1>
<h2>1. Random Forest</h2>
<div class="box">
    
    <p>
        A Random Forest binary classifier is trained, resulting in multiple classifiers. After training, the classifiers are used to collect the probability scores of each instance in the test set for each class and the class with the highest probability is then selected for each test instance where it calculates and displays metrics—accuracy, precision, recall, and F1-score—for each of the binary classifiers on the test set.
    </p><br>
    <p class="placeholder"><img src="assets/m1.png" width="500" class="center"></p><br>
    <p>
        Printed the overall accuracy of the Random Forest classifier across all classes. Models like gpt-4-0125-preview and llama-3-70b-instruct show high precision, recall, and F1-scores, while models like chatgpt-4o-latest underperformed. Most of the models have moderate performance, with scores ranging from 0.60 to 0.80.
    </p><br>
    <p class="placeholder"><img src="assets/m1_2.png" width="500" class="center"></p>
    <p class="placeholder"><img src="assets/m5.png" width="500" class="center"></p><br>
    <p>
        The matrix provides a view of how well each model is performing relative to others in predicting different classes. The area under each curve (AUC) is an indicator of how well the model can distinguish between classes, with values closer to 1 indicating better performance.
    </p><br>
    <p class="placeholder"><img src="assets/m3.png" width="500" class="center"></p><br><br>
    <p class="placeholder"><img src="assets/m4.png" width="500" class="center"></p><br>
</div>

<h2>2. XGBoost</h2>
<div class="box">
    
    <p>
        The XGBoost classifier achieved an overall accuracy of 0.68. We have used XGBoost for a multi-class classification using a One-vs-Rest approach. The process involves the following steps: Data Loading and Preprocessing, Hyperparameter Tuning using RandomizedSearchCV to tune hyperparameters and selecting the best parameters. Then it trains separate One-vs-Rest XGBoost classifiers for each class. Making predictions involves calculating overall accuracy, a classification report for precision, recall, and F1-score, and visualizing the confusion matrix. Additionally, AUC-ROC curves are plotted.
    </p><br>
    <p class="placeholder"><img src="assets/m6.png" width="800" class="center"></p><br>
    <p>
        The diagonal values, which show the highest numbers (e.g., 603 for the first class), indicate correct predictions.
    </p><br>
    <p class="placeholder"><img src="assets/m7.png" width="500" class="center"></p><br>
    <p>
        The curves closer to the top-left corner of the plot indicate better performance, with AUC values closer to 1.0.
    </p><br>
    <p class="placeholder"><img src="assets/m8.png" width="500" class="center"></p><br>
</div>


<h2>3. CatBoost</h2>
<div class="box">
    
    <p>
        The CatBoost classifier achieved an overall accuracy of 0.66. We have used CatBoost for a multi-class classification using a One-vs-Rest approach. The process includes the following steps: Data Loading and Preprocessing, Hyperparameter Tuning using RandomizedSearchCV to tune hyperparameters and selecting the best parameters. Then it trains separate CatBoost classifiers for each class. Making predictions involves calculating overall accuracy, a classification report for precision, recall, and F1-score, and visualizing the confusion matrix. Additionally, AUC-ROC curves are plotted.
    </p><br>
    <p class="placeholder"><img src="assets/m9.png" width="800" class="center"></p><br><br>
    <p class="placeholder"><img src="assets/m10.png" width="500" class="center"></p><br>
    <p>
        The Area Under the Curve (AUC) where values close to 1 indicate high ability and values closer to 0.5 suggest no better than random performance.
    </p><br>
    <p class="placeholder"><img src="assets/m11.png" width="500" class="center"></p><br>
</div>

<h2>4. LightGBM</h2>
<div class="box">
    <p>
        The LightGBM classifier achieved an overall accuracy of 0.68. The process uses LightGBM for a multi-class classification through a One-vs-Rest approach and involves the following steps: Data Loading and Preprocessing, Hyperparameter Tuning using RandomizedSearchCV with 150 iterations and 5-fold cross-validation to tune hyperparameters and selecting the best parameters. Then, using the One-vs-Rest method, separate LightGBM classifiers are trained. Evaluating the results includes analyzing confusion matrices, classification reports, and AUC-ROC curves.
    </p><br>
    <p class="placeholder"><img src="assets/m12.png" width="800" class="center"></p><br>
    <p>
        High diagonal values suggest that the classifier performs well in predicting those classes, whereas high off-diagonal values indicate areas where the classifier confuses one class for another.
    </p><br>
    <p class="placeholder"><img src="assets/m13.png" width="500" class="center"></p><br>
    <p>
        Values close to 1 indicate excellent ability, while values near 0.5 suggest no better accuracy than random guessing.
    </p><br>
    <p class="placeholder"><img src="assets/m14.png" width="500" class="center"></p><br>
</div>

<h2>5. Voting</h2>
<div class="box">
    
    <p>
        The Voting classifier achieved an overall accuracy of 0.69. We handled a multi-class classification by utilizing a Voting Classifier, combining LightGBM, CatBoost, and XGBoost through a One-vs-Rest (OvR) strategy. The process includes the following steps: Data Loading and Preprocessing, Model Initialization where it initializes three models—LightGBM, CatBoost, and XGBoost—with hyperparameters, which constructs a Voting Classifier using soft voting from all three models. Then, train the One-vs-Rest Model with multiple Voting Classifiers in a One-vs-Rest approach. Evaluating the results includes analyzing confusion matrices and classification reports.
    </p><br>
    <p class="placeholder"><img src="assets/m15.png" width="500" class="center"></p><br>
    <p>
        The numbers on the matrix diagonal (e.g., 608 for the first class) indicate correct predictions for each class, while off-diagonal numbers represent misclassifications.
    </p><br>
    <p class="placeholder"><img src="assets/m16.png" width="500" class="center"></p><br>
</div>

<h2>Accuracy Achieved by Each Model</h2>
<div class="box">
    <table style="width:100%; border-collapse: collapse;">
        <tr>
            <th style="background-color: black; color: white; padding: 10px;">MODEL NAME</th>
            <th style="background-color: black; color: white; padding: 10px;">ACCURACY</th>
        </tr>
        <tr>
            <td style="text-align: center; border: 1px solid black; padding: 10px;">RANDOM FOREST</td>
            <td style="text-align: center; border: 1px solid black; padding: 10px;">0.69</td>
        </tr>
        <tr>
            <td style="text-align: center; border: 1px solid black; padding: 10px;">XG BOOST</td>
            <td style="text-align: center; border: 1px solid black; padding: 10px;">0.68</td>
        </tr>
        <tr>
            <td style="text-align: center; border: 1px solid black; padding: 10px;">CATBOOST</td>
            <td style="text-align: center; border: 1px solid black; padding: 10px;">0.66</td>
        </tr>
        <tr>
            <td style="text-align: center; border: 1px solid black; padding: 10px;">LIGHTGBM</td>
            <td style="text-align: center; border: 1px solid black; padding: 10px;">0.68</td>
        </tr>
        <tr>
            <td style="text-align: center; border: 1px solid black; padding: 10px;">VOTING</td>
            <td style="text-align: center; border: 1px solid black; padding: 10px;">0.69</td>
        </tr>
    </table>
</div>

<br><br><br><br>
<footer>
    <p style="color: #ffffff;">Copyright &#169; 2024 Benchmark Studio. All Rights Reserved.</p>
</footer>
</body>
    </body>
    </html>